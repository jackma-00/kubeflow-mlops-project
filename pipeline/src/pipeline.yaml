apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18, pipelines.kubeflow.org/pipeline_compilation_time: '2022-12-21T17:56:33.925617',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "This simple pipeline wants
      to test the custom created components, as well as the CI/CD operations", "name":
      "pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18}
spec:
  entrypoint: pipeline
  templates:
  - name: load-data
    container:
      command: [python, load_dataset.py]
      image: jackma00/load-dataset:latest
    outputs:
      artifacts:
      - {name: load-data-raw_dataset, path: raw_dataset.csv}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
  - name: normalize-data
    container:
      args: [--raw_dataset, /tmp/inputs/input-0/data]
      command: [python, normalize_dataset.py]
      image: jackma00/normalize-dataset:latest
    inputs:
      artifacts:
      - {name: load-data-raw_dataset, path: /tmp/inputs/input-0/data}
    outputs:
      artifacts:
      - {name: normalize-data-normalized_dataset, path: normalized_dataset.csv}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
  - name: pipeline
    dag:
      tasks:
      - {name: load-data, template: load-data}
      - name: normalize-data
        template: normalize-data
        dependencies: [load-data]
        arguments:
          artifacts:
          - {name: load-data-raw_dataset, from: '{{tasks.load-data.outputs.artifacts.load-data-raw_dataset}}'}
  arguments:
    parameters: []
  serviceAccountName: pipeline-runner
